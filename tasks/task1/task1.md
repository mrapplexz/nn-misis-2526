# ДЗ №1

https://www.kaggle.com/competitions/playground-series-s4e10/overview

Прикладываю заранее разбитый на train и на test датасет, чтобы у всех тестовые метрики по одной и той же выборке считались - лежат в файлах `loan_test.csv` и `loan_train.csv`

Задача - по признакам клиента понять, можно ли данному клиенту давать займ или нет - бинарная классификация.

В качестве метрики рассчитывать ROC-AUC. Для каждого эксперимент логировать график loss'а и метрики на train'е и на test'е.

Поставить эксперименты с глубокой моделью:

## Эксперимент 1. Простая модель

### Архитектура
1. все входные данные в hidden_size - Linear и Embedding слои в помощь :)
2. Простой блок
3. Linear (hidden size в выход)

### Простой блок
1. Linear (hidden size в hidden size * 4)
2. ReLU
3. Linear (hidden size * 4 в hidden size)

### Параметры
* hidden size = 32
* SGD c lr = 0.01
* количество эпох = 10
* batch size = 32
* seed - выбираете любой

### Задача

* Обучить такую модель
* Подобрать оптимальное количество эпох
* **Ответить на вопрос**: Как ведёт себя модель по мере обучения? Сколько эпох оптимально?

## Эксперимент 2. Модель побольше

### Задача
* Как прошлый эксперимент, но попробовать увеличить hidden size до 128 и сделать не 1 блок, а 3.
* **Ответить на вопрос**: Стало ли лучше? Как теперь ведёт себя модель?

## Эксперимент 3. Skip Connections, Batch Norms

### Задача
* Как прошлый эксперимент, но добавить Skip Connection от входа блока к его выходу, а также Batch Norm в начале каждого блока.
* **Ответить на вопрос**: Стало ли лучше? Как теперь ведёт себя модель?

## Эксперимент 4. Dropout

### Задача
* Как прошлый эксперимент, но добавить dropout внутрь блока и подобрать оптимальный p для него (можно среди 0.01, 0.1, 0.2, 0.5, 0.9)
* **Ответить на вопрос**: Как меняется качество модели в зависимости от p? Как ведёт себя модель с разными p?

## Эксперимент 5. Weight Decay, Learning Rate
* Как прошлый эксперимент, но включить weight decay и подобрать оптимальную пару: lambda для weight decay и оптимальный learning rate. Weight Decay можно перебрать среди (0.1, 0.01, 0.001), Learning Rate среди (0.01, 0.05, 0.1).
* **Ответить на вопрос**: Как зависит качество итоговой модели от этих двух параметров? Как ведёт себя модель с разными lambda и lr?

## Сдача

Код для воспроизведения экспериментов (чтобы можно было запустить разные train.py и воспроизвести результаты) в виде ссылки на GitHub репозиторий нужно отправить мне в личку в телеграм.
В readme.md в репозитории укажите результаты экспериментов (метрики и значения функции ошибки) и ответы с небольшим пояснением на вопросы для каждого эксперимента.

### Баллы
Если сделаете только первый эксперимент - можно получить 3 балла. Если 1-3 - 4 балла. Если 1-5 - 5 баллов

### Дедлайн

Сдавать и корректировать решение можно до 31 марта.
